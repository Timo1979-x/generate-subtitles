1
00:00:00,000 --> 00:00:06,320
You have completed this course, assuming you have watched all the lectures in the given

2
00:00:06,320 --> 00:00:07,320
order.

3
00:00:07,320 --> 00:00:08,960
So what is next?

4
00:00:08,960 --> 00:00:14,360
Sometimes people will ask me via private message that, hey Vinod can you suggest what I should

5
00:00:14,360 --> 00:00:17,260
learn next, something like that.

6
00:00:17,260 --> 00:00:23,420
I have created few courses and I can explain on what basis I created them so that you can

7
00:00:23,420 --> 00:00:27,800
pick the next topic which interests you.

8
00:00:27,800 --> 00:00:31,560
Let's consider an application with microservices architecture here.

9
00:00:31,560 --> 00:00:36,040
We have a bunch of services talking to one another like this.

10
00:00:36,040 --> 00:00:42,160
Let's say we are receiving hundreds of thousands of requests per minute here.

11
00:00:42,160 --> 00:00:48,120
How can we process all these requests more efficiently without launching or before horizontally

12
00:00:48,120 --> 00:00:49,960
scaling another instance?

13
00:00:49,960 --> 00:00:55,080
How can we make use of the given CPU or memory properly?

14
00:00:55,080 --> 00:00:57,620
Here we have two options.

15
00:00:57,620 --> 00:01:00,419
One is using Java virtual thread.

16
00:01:00,419 --> 00:01:05,620
Java finally after many years they have introduced virtual threads.

17
00:01:05,620 --> 00:01:12,620
Using virtual threads we write synchronous blocking style code but Java will do non-blocking

18
00:01:12,620 --> 00:01:17,220
I O for us to process requests more efficiently.

19
00:01:17,220 --> 00:01:18,860
I have a course on that.

20
00:01:18,860 --> 00:01:20,580
Check that out.

21
00:01:20,580 --> 00:01:26,000
Another option is developing reactive microservice with Spring WebFlex.

22
00:01:26,000 --> 00:01:29,880
The whole reactive paradigm is kind of new.

23
00:01:29,880 --> 00:01:34,560
Different style of programming and reactive programming enables us to do stream based

24
00:01:34,560 --> 00:01:35,560
communication.

25
00:01:35,560 --> 00:01:41,120
It's very hard to achieve with the synchronous blocking style code.

26
00:01:41,120 --> 00:01:47,600
So by using either of these options we can develop one single microservice which should

27
00:01:47,600 --> 00:01:52,560
be capable of processing requests more efficiently.

28
00:01:52,560 --> 00:01:56,400
Microservices are great, easy to develop, test and deploy.

29
00:01:56,400 --> 00:02:01,720
But when we create multiple microservices under talking to one another like this there

30
00:02:01,720 --> 00:02:07,280
will be network latency and it will affect the overall application processing time.

31
00:02:07,280 --> 00:02:11,140
How can we improve our back end communication?

32
00:02:11,140 --> 00:02:14,800
For the back end communication I can suggest three options.

33
00:02:14,800 --> 00:02:18,320
The one is gRPC created by Google.

34
00:02:18,320 --> 00:02:20,060
They have been using it for years.

35
00:02:20,060 --> 00:02:27,200
It uses protocol buffers and HTTP2 to reduce the network latency and improve the application

36
00:02:27,200 --> 00:02:30,020
throughput, response time etc.

37
00:02:30,020 --> 00:02:31,380
So this is great.

38
00:02:31,380 --> 00:02:32,740
You can check this out.

39
00:02:32,740 --> 00:02:34,740
The next one is rSocket.

40
00:02:34,740 --> 00:02:41,240
It's almost same as this gRPC but it's reactive style.

41
00:02:41,240 --> 00:02:43,260
This one is from Netflix.

42
00:02:43,260 --> 00:02:47,740
This is also great for the back end communication.

43
00:02:47,740 --> 00:02:53,380
If you like messaging for the asynchronous communication among microservices then we

44
00:02:53,380 --> 00:02:56,940
can also go with Kafka.

45
00:02:56,940 --> 00:03:01,700
We can compare these but before that let me clarify one thing.

46
00:03:01,700 --> 00:03:04,020
What is stream based communication?

47
00:03:04,020 --> 00:03:10,180
Traditionally our programming style or our application communication will be like client

48
00:03:10,180 --> 00:03:16,700
will send one request for which the server will give us one response back.

49
00:03:16,700 --> 00:03:19,239
This is how normally we do things.

50
00:03:19,239 --> 00:03:25,700
In the stream based communication it will be like two people talking to one another

51
00:03:25,700 --> 00:03:27,920
via phone.

52
00:03:27,920 --> 00:03:30,420
The client will call the server.

53
00:03:30,420 --> 00:03:36,140
Once the connection is established they can exchange information continuously.

54
00:03:36,140 --> 00:03:39,940
So we can design interactive application.

55
00:03:39,940 --> 00:03:45,660
Now we can compare the various technologies or options we have for the back end communication.

56
00:03:45,660 --> 00:03:48,420
If we want RESTful APIs we have two options.

57
00:03:48,420 --> 00:03:53,460
We can go with the Spring Web for the synchronous blocking style code and you will get request

58
00:03:53,460 --> 00:03:58,519
and response style programming but it's very hard to achieve stream based communication.

59
00:03:58,519 --> 00:04:03,060
If you want stream based communication along with the RESTful APIs then we can go with

60
00:04:03,060 --> 00:04:04,560
the Spring WebFlex.

61
00:04:04,560 --> 00:04:08,460
That is where the reactive programming shines.

62
00:04:08,460 --> 00:04:15,100
If you do not like REST or for the back end communication things do not have to be RESTful

63
00:04:15,100 --> 00:04:16,860
actually.

64
00:04:16,860 --> 00:04:24,340
If you want low latency which I would highly encourage you to try these for the low latency

65
00:04:24,340 --> 00:04:29,940
communication we can have gRPC which will provide the request and response, stream based

66
00:04:29,940 --> 00:04:33,219
communication etc.

67
00:04:33,219 --> 00:04:36,980
Then we have RSocket same as this one but it's reactive.

68
00:04:36,980 --> 00:04:40,620
gRPC uses HTTP2 it's a network level 7.

69
00:04:40,620 --> 00:04:43,040
RSocket is the custom protocol.

70
00:04:43,040 --> 00:04:49,540
It uses network level 5 so because of that in theory RSocket should provide better performance

71
00:04:49,540 --> 00:04:51,680
compared to gRPC.

72
00:04:51,680 --> 00:04:55,260
However gRPC is not really tied to HTTP2.

73
00:04:55,260 --> 00:04:59,800
In the future they might change the protocol as well.

74
00:04:59,800 --> 00:05:06,640
So you can't go wrong with either of these actually.

75
00:05:06,640 --> 00:05:12,960
Then we have Kafka for the completely even driven asynchronous communication.

76
00:05:12,960 --> 00:05:15,239
What about the communication with the front end?

77
00:05:15,239 --> 00:05:19,859
We have browser and mobile application etc. talk to the back end.

78
00:05:19,859 --> 00:05:22,060
So what can we do here?

79
00:05:22,060 --> 00:05:28,479
I can suggest GraphQL here to avoid some of the challenges with the RESTful APIs and for

80
00:05:28,479 --> 00:05:31,320
efficient data retrieval.

81
00:05:31,320 --> 00:05:36,159
I have one dedicated course on GraphQL check that out.

82
00:05:36,160 --> 00:05:43,840
Basically for mobile applications the gRPC and RSocket can also work great here as they

83
00:05:43,840 --> 00:05:46,120
are lightweight.

84
00:05:46,120 --> 00:05:52,200
Then what else I can do to improve my application throughput and reduce redundant work.

85
00:05:52,200 --> 00:05:59,620
We can also add Redis which is high performance caching layer which provides super fast read

86
00:05:59,620 --> 00:06:00,620
write operations.

87
00:06:00,620 --> 00:06:06,420
We can add Redis in our architecture to improve the application throughput and the response

88
00:06:06,420 --> 00:06:07,420
time.

89
00:06:07,420 --> 00:06:14,820
It can also provide features like PubSub messaging, distributed locking among microservices.

90
00:06:14,820 --> 00:06:17,900
We have to be careful when we design our application.

91
00:06:17,900 --> 00:06:20,340
Anything could happen in the network.

92
00:06:20,340 --> 00:06:25,980
One service might be very slow or one service might fail suddenly.

93
00:06:25,980 --> 00:06:30,940
The problem in one service should not propagate everywhere.

94
00:06:30,940 --> 00:06:37,900
It is always our responsibility to design our application to be highly resilient.

95
00:06:37,900 --> 00:06:43,020
There are some techniques, design patterns we can follow to develop highly resilient

96
00:06:43,020 --> 00:06:44,020
applications.

97
00:06:44,020 --> 00:06:50,340
I have documented that in this course Microservices Design Patterns.

98
00:06:50,340 --> 00:06:54,880
Integration and Resilient Design Patterns for Microservices Architecture.

99
00:06:54,880 --> 00:06:56,040
What about testing?

100
00:06:56,040 --> 00:07:02,640
I have a course on Selenium and running automated UI test via CI-CD pipeline.

101
00:07:02,640 --> 00:07:05,780
I use Jenkins in this course.

102
00:07:05,780 --> 00:07:08,560
You can check that out if you are interested.

103
00:07:08,560 --> 00:07:13,640
Ok we have developed our application which is scalable, performant etc.

104
00:07:13,640 --> 00:07:16,880
So what about deployment, service discovery?

105
00:07:16,880 --> 00:07:20,920
Here I would suggest Docker and Kubernetes.

106
00:07:20,920 --> 00:07:23,300
Docker is a must know tool if you ask me.

107
00:07:23,300 --> 00:07:28,700
If you have never tried Docker you will be amazed how it can increase our productivity

108
00:07:28,700 --> 00:07:34,060
by quickly spinning up the dependent application like databases or other applications for local

109
00:07:34,060 --> 00:07:35,200
development.

110
00:07:35,200 --> 00:07:40,420
It is easy to package, deploy, share applications via Docker.

111
00:07:40,420 --> 00:07:46,860
Kubernetes is for orchestration, for service discovery, load balancing, rolling update,

112
00:07:46,860 --> 00:07:52,900
rollback, configuration management, another super important feature, auto scaling.

113
00:07:52,900 --> 00:08:00,099
We definitely should not want to lock ourselves with one particular cloud provider like AWS

114
00:08:00,099 --> 00:08:02,539
or GCP etc.

115
00:08:02,539 --> 00:08:10,780
Kubernetes is the way to develop applications which can provide multi cloud support.

116
00:08:10,780 --> 00:08:12,380
I have one course on Kubernetes.

117
00:08:12,380 --> 00:08:15,400
We will learn Kubernetes in the end.

118
00:08:15,400 --> 00:08:21,940
You will see in less than 10 minutes we will run our application on GCP cloud without doing

119
00:08:21,980 --> 00:08:22,980
much.

120
00:08:22,980 --> 00:08:29,940
Auto scaling, service discovery etc. will work just out of the box with Kubernetes configuration.

121
00:08:29,940 --> 00:08:34,340
To quickly summarize, these are the topics for which I have courses for now.

122
00:08:34,340 --> 00:08:37,500
Pause this video if you want to review.

123
00:08:37,500 --> 00:08:44,900
Once you picked up the next topic, if you go to my profile in this Udemy platform, then

124
00:08:44,900 --> 00:08:48,280
you should be able to find all the courses.

125
00:08:48,280 --> 00:08:50,020
Thanks and I will see you soon.

126
00:08:51,940 --> 00:08:52,940
Thank you.


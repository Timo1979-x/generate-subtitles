1
00:00:00,000 --> 00:00:06,160
You have completed this course assuming you have watched all the lectures in the given

2
00:00:06,160 --> 00:00:07,160
order.

3
00:00:07,160 --> 00:00:09,220
So what is next?

4
00:00:09,220 --> 00:00:14,360
Sometimes people will ask me via private message that hey Vinod can you suggest what I should

5
00:00:14,360 --> 00:00:15,680
learn next?

6
00:00:15,680 --> 00:00:17,260
Something like that.

7
00:00:17,260 --> 00:00:23,440
I have created few courses and I can explain on what basis I created them so that you can

8
00:00:23,440 --> 00:00:27,800
pick the next topic which interests you.

9
00:00:27,800 --> 00:00:31,560
Let's consider an application with the microservices architecture here.

10
00:00:31,560 --> 00:00:36,040
We have a bunch of services talking to one another like this.

11
00:00:36,040 --> 00:00:42,160
Let's say we are receiving hundreds of thousands of requests per minute here.

12
00:00:42,160 --> 00:00:48,120
How can we process all these requests more efficiently without launching or before horizontally

13
00:00:48,120 --> 00:00:49,960
scaling another instance?

14
00:00:49,960 --> 00:00:55,080
How can we make use of the given CPU or memory properly?

15
00:00:55,080 --> 00:00:57,600
Here we have two options.

16
00:00:57,600 --> 00:01:00,480
One is using Java Virtual Thread.

17
00:01:00,480 --> 00:01:05,600
Java finally after many years they have introduced virtual threads.

18
00:01:05,600 --> 00:01:12,600
Using virtual threads we write synchronous blocking style code but Java will do non-blocking

19
00:01:12,600 --> 00:01:17,200
IO for us to process requests more efficiently.

20
00:01:17,200 --> 00:01:19,000
I have a course on that.

21
00:01:19,000 --> 00:01:20,560
Check that out.

22
00:01:20,560 --> 00:01:25,980
Another option is developing reactive microservice with the Spring WebFlex.

23
00:01:25,980 --> 00:01:29,860
The whole reactive paradigm is kind of new.

24
00:01:29,860 --> 00:01:34,580
Different style of programming and reactive programming enables us to do stream based

25
00:01:34,580 --> 00:01:35,580
communication.

26
00:01:35,580 --> 00:01:41,140
It's very hard to achieve with the synchronous blocking style code.

27
00:01:41,140 --> 00:01:47,580
So by using either of these options we can develop one single microservice which should

28
00:01:47,580 --> 00:01:52,580
be capable of processing requests more efficiently.

29
00:01:52,580 --> 00:01:56,420
Microservices are great, easy to develop, test and deploy.

30
00:01:56,420 --> 00:02:01,780
But when we create multiple microservices under talking to one another like this, there

31
00:02:01,780 --> 00:02:07,300
will be network latency and it will affect the overall application processing time.

32
00:02:07,300 --> 00:02:11,180
How can we improve our backend communication?

33
00:02:11,180 --> 00:02:14,820
For the backend communication I can suggest three options.

34
00:02:14,820 --> 00:02:18,340
The one is GRPC created by Google.

35
00:02:18,340 --> 00:02:20,079
They have been using it for years.

36
00:02:20,080 --> 00:02:27,240
It uses protocol buffers and HTTP2 to reduce the network latency and improve the application

37
00:02:27,240 --> 00:02:30,020
throughput, response time etc.

38
00:02:30,020 --> 00:02:31,360
So this is great.

39
00:02:31,360 --> 00:02:32,720
You can check this out.

40
00:02:32,720 --> 00:02:34,760
The next one is R-Socket.

41
00:02:34,760 --> 00:02:41,240
It's almost same as this GRPC but it's reactive style.

42
00:02:41,240 --> 00:02:43,240
This one is from Netflix.

43
00:02:43,240 --> 00:02:47,720
This is also great for the backend communication.

44
00:02:47,720 --> 00:02:53,400
If you like messaging for the asynchronous communication among microservices then we

45
00:02:53,400 --> 00:02:56,920
can also go with Kafka.

46
00:02:56,920 --> 00:03:01,700
We can compare these but before that let me clarify one thing.

47
00:03:01,700 --> 00:03:04,040
What is stream based communication?

48
00:03:04,040 --> 00:03:10,160
Traditionally our programming style or our application communication will be like client

49
00:03:10,160 --> 00:03:16,700
will send one request for which the server will give us one response back.

50
00:03:16,700 --> 00:03:19,260
This is how normally we do things.

51
00:03:19,260 --> 00:03:25,700
In the stream based communication it will be like two people talking to one another

52
00:03:25,700 --> 00:03:27,920
via phone.

53
00:03:27,920 --> 00:03:30,420
The client will call the server.

54
00:03:30,420 --> 00:03:36,140
Once the connection is established they can exchange information continuously.

55
00:03:36,140 --> 00:03:39,940
So we can design interactive application.

56
00:03:39,940 --> 00:03:45,660
Now we can compare the various technologies or options we have for the backend communication.

57
00:03:45,660 --> 00:03:48,460
If we want RESTful APIs we have two options.

58
00:03:48,460 --> 00:03:53,500
We can go with Spring Web for the synchronous blocking style code and you will get request

59
00:03:53,500 --> 00:03:58,560
and response style programming but it's very hard to achieve stream based communication.

60
00:03:58,560 --> 00:04:03,740
If we want stream based communication along with RESTful APIs then we can go with Spring

61
00:04:03,740 --> 00:04:04,740
Web Flex.

62
00:04:04,740 --> 00:04:08,500
That is where the reactive programming shines.

63
00:04:08,500 --> 00:04:15,140
If we do not like REST or for the backend communication things do not have to be RESTful

64
00:04:15,140 --> 00:04:16,860
actually.

65
00:04:16,860 --> 00:04:24,340
If we want low latency which I would highly encourage you to try these for the low latency

66
00:04:24,340 --> 00:04:29,940
communication we can have gRPC which will provide the request and response stream based

67
00:04:29,940 --> 00:04:33,219
communication etc.

68
00:04:33,219 --> 00:04:36,940
Then we have R-Circuit same as this one but it's reactive.

69
00:04:36,940 --> 00:04:40,620
gRPC uses HTTP2 it's a network level 7.

70
00:04:40,620 --> 00:04:43,020
R-Circuit is the custom protocol.

71
00:04:43,020 --> 00:04:48,900
It uses network level 5 so because of that in theory R-Circuit should provide better

72
00:04:48,900 --> 00:04:51,700
performance compared to gRPC.

73
00:04:51,700 --> 00:04:55,260
However gRPC is not really tied to HTTP2.

74
00:04:55,260 --> 00:04:59,820
In the future they might change the protocol as well.

75
00:04:59,820 --> 00:05:06,620
So you can't go wrong with the either of these actually.

76
00:05:06,620 --> 00:05:12,940
Then we have Kafka for the completely even driven asynchronous communication.

77
00:05:12,940 --> 00:05:15,300
What about the communication with the front end?

78
00:05:15,300 --> 00:05:18,780
We have browser and mobile application etc.

79
00:05:18,780 --> 00:05:19,860
Talk to the backend.

80
00:05:19,860 --> 00:05:22,060
So what can we do here?

81
00:05:22,060 --> 00:05:28,020
I can suggest GraphQL here to avoid some of the challenges with the RESTful APIs and

82
00:05:28,020 --> 00:05:31,340
for efficient data retrieval.

83
00:05:31,340 --> 00:05:34,500
I have one dedicated course on GraphQL.

84
00:05:34,500 --> 00:05:36,140
Check that out.

85
00:05:36,140 --> 00:05:43,700
Especially for mobile applications the gRPC and R-Circuit can also work great here as

86
00:05:43,700 --> 00:05:46,099
they are lightweight.

87
00:05:46,099 --> 00:05:52,180
Then what else I can do to improve my application throughput and reduce redundant work.

88
00:05:52,180 --> 00:05:59,620
We can also add Redis which is high performance caching layer which provides super fast read

89
00:05:59,620 --> 00:06:00,620
write operations.

90
00:06:00,620 --> 00:06:06,420
We can add Redis in our architecture to improve the application throughput and the response

91
00:06:06,420 --> 00:06:07,420
time.

92
00:06:07,420 --> 00:06:13,820
It can also provide features like pub sub messaging, distributed locking among microservices.

93
00:06:13,820 --> 00:06:17,900
We have to be careful when we design our application.

94
00:06:17,900 --> 00:06:20,340
Anything could happen in the network.

95
00:06:20,340 --> 00:06:25,980
One service might be very slow or one service might fail suddenly.

96
00:06:25,980 --> 00:06:30,940
The problem in one service should not propagate everywhere.

97
00:06:30,940 --> 00:06:37,900
It is always our responsibility to design our application to be highly resilient.

98
00:06:37,900 --> 00:06:43,020
There are some techniques design patterns we can follow to develop highly resilient

99
00:06:43,020 --> 00:06:44,020
application.

100
00:06:44,020 --> 00:06:51,580
I have documented that in this course microservices design patterns, integration and resilient

101
00:06:51,580 --> 00:06:54,860
design patterns for microservices architecture.

102
00:06:54,860 --> 00:06:56,020
What about testing?

103
00:06:56,020 --> 00:07:02,620
I have a course on Selenium, the running automated UI test via CI-CD pipeline.

104
00:07:02,620 --> 00:07:05,760
I use Jenkins in this course.

105
00:07:05,760 --> 00:07:08,020
You can check that out if you are interested.

106
00:07:08,020 --> 00:07:13,620
Ok, we have developed our application which is scalable, performant etc.

107
00:07:13,620 --> 00:07:16,860
So what about deployment, service discovery.

108
00:07:16,860 --> 00:07:20,900
Here I would suggest Docker and Kubernetes.

109
00:07:20,900 --> 00:07:23,300
Docker is a must know tool if you ask me.

110
00:07:23,300 --> 00:07:28,700
If you have never tried Docker, you will be amazed how it can increase our productivity

111
00:07:28,700 --> 00:07:34,060
by quickly spinning up the dependent application like databases or other applications for local

112
00:07:34,060 --> 00:07:35,180
development.

113
00:07:35,180 --> 00:07:40,420
It is easy to package, deploy, share applications via Docker.

114
00:07:40,420 --> 00:07:46,980
Kubernetes is for orchestration, for service discovery, load balancing, rolling update,

115
00:07:46,980 --> 00:07:52,340
rollback, configuration management, another super important feature, auto scaling.

116
00:07:52,859 --> 00:08:00,099
We definitely should not want to lock ourselves with one particular cloud provider like AWS

117
00:08:00,099 --> 00:08:02,580
or GCP etc.

118
00:08:02,580 --> 00:08:10,780
Kubernetes is the way to develop applications which can provide multi-cloud support.

119
00:08:10,780 --> 00:08:12,859
I have one course on this Kubernetes.

120
00:08:12,859 --> 00:08:14,620
We will learn Kubernetes.

121
00:08:14,620 --> 00:08:21,500
In the end you will see in less than 10 minutes we will run our application on GCP cloud without

122
00:08:21,500 --> 00:08:22,940
doing much.

123
00:08:22,940 --> 00:08:29,940
Auto scaling, service discovery etc. will work just out of the box with the Kubernetes configuration.

124
00:08:29,940 --> 00:08:34,340
To quickly summarize, these are the topics for which I have courses for now.

125
00:08:34,340 --> 00:08:37,500
Pause this video if you want to review.

126
00:08:37,500 --> 00:08:44,900
Once you picked up the next topic, if you go to my profile in this Udemy platform, then

127
00:08:44,900 --> 00:08:48,260
you should be able to find all the courses.

128
00:08:48,260 --> 00:08:49,980
Thanks and I will see you soon.

129
00:08:51,500 --> 00:08:52,500
Thank you.

